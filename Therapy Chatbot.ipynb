{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "divided-affair",
   "metadata": {},
   "source": [
    "## Therapy Chatbot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "warming-turkey",
   "metadata": {},
   "source": [
    "### Libraries and Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "representative-saint",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasets\\Sheet_1.csv\n",
      "datasets\\Sheet_2.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\abhil\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download(\"stopwords\") \n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('datasets'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adjustable-handbook",
   "metadata": {},
   "source": [
    "### Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "swedish-iceland",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>response_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>not_flagged</td>\n",
       "      <td>I try and avoid this sort of conflict</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>flagged</td>\n",
       "      <td>Had a friend open up to me about his mental ad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>flagged</td>\n",
       "      <td>I saved a girl from suicide once. She was goin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>not_flagged</td>\n",
       "      <td>i cant think of one really...i think i may hav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>not_flagged</td>\n",
       "      <td>Only really one friend who doesn't fit into th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>not_flagged</td>\n",
       "      <td>a couple of years ago my friends was going to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>flagged</td>\n",
       "      <td>Roommate when he was going through death and l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>flagged</td>\n",
       "      <td>i've had a couple of friends (you could say mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>not_flagged</td>\n",
       "      <td>Listened to someone talk about relationship tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>flagged</td>\n",
       "      <td>I will always listen. I comforted my sister wh...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         class                                      response_text\n",
       "0  not_flagged              I try and avoid this sort of conflict\n",
       "1      flagged  Had a friend open up to me about his mental ad...\n",
       "2      flagged  I saved a girl from suicide once. She was goin...\n",
       "3  not_flagged  i cant think of one really...i think i may hav...\n",
       "4  not_flagged  Only really one friend who doesn't fit into th...\n",
       "5  not_flagged  a couple of years ago my friends was going to ...\n",
       "6      flagged  Roommate when he was going through death and l...\n",
       "7      flagged  i've had a couple of friends (you could say mo...\n",
       "8  not_flagged  Listened to someone talk about relationship tr...\n",
       "9      flagged  I will always listen. I comforted my sister wh..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(r\"datasets/Sheet_1.csv\",encoding= \"latin1\" )\n",
    "data.drop([\"Unnamed: 3\",\"Unnamed: 4\",\"Unnamed: 5\",\n",
    "           \"Unnamed: 6\",\"Unnamed: 7\",], axis = 1, inplace =True)\n",
    "data = pd.concat([data[\"class\"],data[\"response_text\"]], axis = 1)\n",
    "\n",
    "data.dropna(axis=0, inplace =True)\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prostate-gossip",
   "metadata": {},
   "source": [
    "### 0 to Not Flagged and 1 to Flagged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ceramic-release",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>response_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>I try and avoid this sort of conflict</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Had a friend open up to me about his mental ad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>I saved a girl from suicide once. She was goin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>i cant think of one really...i think i may hav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Only really one friend who doesn't fit into th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   class                                      response_text\n",
       "0      0              I try and avoid this sort of conflict\n",
       "1      1  Had a friend open up to me about his mental ad...\n",
       "2      1  I saved a girl from suicide once. She was goin...\n",
       "3      0  i cant think of one really...i think i may hav...\n",
       "4      0  Only really one friend who doesn't fit into th..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"class\"] = [1 if each == \"flagged\" else 0 for each in data[\"class\"]]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "finished-dragon",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I have helped advise friends who have faced circumstances similar to mine'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.response_text[16]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tribal-motion",
   "metadata": {},
   "source": [
    "## Regular Expression\n",
    "#### We can remove non-letter characters in our text with Regular Expression method.\n",
    "#### The lower() methods returns the lowercased string from the given string. It converts all uppercase characters to lowercase. If no uppercase characters exist, it returns the original string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "proved-fraction",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i have helped advise friends who have faced circumstances similar to mine\n"
     ]
    }
   ],
   "source": [
    "first_text = data.response_text[16]\n",
    "text = re.sub(\"[^a-zA-Z]\",\" \",first_text)\n",
    "text = text.lower()\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reflected-capability",
   "metadata": {},
   "source": [
    "### Irrelevant Words (Stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "twelve-solomon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['helped', 'advise', 'friends', 'faced', 'circumstances', 'similar', 'mine']\n"
     ]
    }
   ],
   "source": [
    "text = nltk.word_tokenize(text)\n",
    "text = [ word for word in text if not word in set(stopwords.words('english'))]\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abroad-dylan",
   "metadata": {},
   "source": [
    "### Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "central-viewer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['help', 'advise', 'friend', 'face', 'circumstance', 'similar', 'mine']\n"
     ]
    }
   ],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "text = [(lemmatizer.lemmatize(lemmatizer.lemmatize(lemmatizer.lemmatize(word,'n'),pos = 'v'),pos = 'a')) for word in text]\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "printable-equity",
   "metadata": {},
   "source": [
    "### All Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "african-locking",
   "metadata": {},
   "outputs": [],
   "source": [
    "description_list = []\n",
    "for description in data.response_text:\n",
    "       \n",
    "    description = re.sub(\"[^a-zA-Z]\",\" \",description)\n",
    "    description = description.lower() \n",
    "    \n",
    "    description = nltk.word_tokenize(description)\n",
    "    description = [ word for word in description if not word in set(stopwords.words(\"english\"))]\n",
    "    \n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    description = (lemmatizer.lemmatize(lemmatizer.lemmatize(lemmatizer.lemmatize(word, \"n\"),pos = \"v\"),pos=\"a\") for word in description)\n",
    "    \n",
    "    description = \" \".join(description)\n",
    "    description_list.append(description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ordered-technician",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'help advise friend face circumstance similar mine'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "description_list[16]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "light-japanese",
   "metadata": {},
   "source": [
    "### Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "automatic-precipitation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 100 Most Used Words: ['addiction', 'advice', 'alone', 'always', 'anxiety', 'anything', 'back', 'best', 'bring', 'call', 'care', 'come', 'comfort', 'could', 'deal', 'depression', 'describe', 'dont', 'end', 'even', 'everything', 'experience', 'face', 'feel', 'find', 'friend', 'get', 'gf', 'girl', 'girlfriend', 'give', 'go', 'good', 'grade', 'happen', 'help', 'helpful', 'issue', 'kid', 'kill', 'know', 'last', 'let', 'life', 'like', 'listen', 'little', 'look', 'lot', 'make', 'many', 'may', 'much', 'need', 'never', 'night', 'offer', 'often', 'one', 'open', 'others', 'people', 'person', 'personal', 'pretty', 'problem', 'really', 'relationship', 'say', 'school', 'see', 'self', 'severe', 'share', 'shit', 'similar', 'simply', 'situation', 'someone', 'sometimes', 'start', 'struggle', 'stuff', 'suicide', 'support', 'talk', 'tell', 'think', 'though', 'time', 'trouble', 'try', 'use', 'want', 'way', 'week', 'well', 'work', 'would', 'year']\n"
     ]
    }
   ],
   "source": [
    "max_features = 100\n",
    "count_vectorizer = CountVectorizer(max_features = max_features)\n",
    "sparce_matrix = count_vectorizer.fit_transform(description_list).toarray()\n",
    "print(\"Top {} Most Used Words: {}\".format(max_features,count_vectorizer.get_feature_names()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prime-newcastle",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "other-hydrogen",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sparce_matrix' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-d7aabf9bb9f0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msparce_matrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'sparce_matrix' is not defined"
     ]
    }
   ],
   "source": [
    "y = data.iloc[:,0].values\n",
    "x = sparce_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "growing-blank",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
